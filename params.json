{"name":"Coursera-pml-final project","tagline":"","body":"---\r\ntitle: \"Final Project\"\r\nauthor: \"Fabrizio Veneziano\"\r\ndate: \"Thursday, July 16, 2015\"\r\noutput: html_document\r\n---\r\n\r\n##Getting the data\r\n\r\nThe training data set can be found on the following URL:\r\n\r\n```{r LoadTrain, cache=TRUE}\r\ntrainUrl <- read.csv(\"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\")\r\n\r\n```\r\n\r\n\r\nThe testing data set can be found on the following URL:\r\n\r\n```{r LoadTest, cache=TRUE}\r\n\r\ntestUrl <- read.csv(\"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\")\r\n\r\n```\r\n\r\n## Data CleanUp\r\n  \r\nBefore proceedeing with the model-bulding section, we take a look at the variables of both data set and remove the ones which we deem irrelevant to our predictions (\"user\", etc.), and also get rid of columns containing NAs: we are planning to use the Rattle/RandomForest method to build our model, and Rby experience we know it doesn't handle NAs very well.  \r\nWe also recode variables and tur them into numeric ones (this step could also be performed in Rattle, but it would add new variable names, making the model inconsistent with the Test set).  \r\n\r\n\r\n```{r CleanUp}\r\n\r\n# names(trainUrl)\r\n# names(testUrl)\r\n \r\ntraining <- trainUrl[,c(8:160)]\r\nclasse <- training$classe\r\ntraining <- training[, sapply(training, is.numeric)]\r\ntraining <- training[, colSums(is.na(training)) == 0] \r\n\r\ntraining <- cbind(training,classe)\r\n\r\nfinalTest <- testUrl[,c(8:160)]\r\nfinalTest <- finalTest[,sapply(finalTest, is.numeric)]\r\nfinalTest <- finalTest[, colSums(is.na(finalTest)) == 0] \r\n\r\n\r\n\r\n```\r\n\r\n## Model building with RandomForest and Rattle package  \r\n\r\nThe Rattle package/GUI makes it easier to visualize the model building process and has some useful built-in functions to 'tweak', analyze and optimize the model.  \r\n\r\nIts output is very informative, although somewhat verbose:\r\n\r\n```{r Rattle}\r\n\r\nlibrary(rattle)\r\n\r\n#rattle()\r\n\r\n\r\n# Rattle output\r\n\r\n\r\n# A pre-defined value is used to reset the random seed so that results are repeatable.\r\n\r\ncrv$seed <- 42 \r\n\r\n \r\n\r\n# Load our R data frame.\r\n\r\npml_dataset <- training\r\n```\r\n \r\n \r\n \r\n\r\n### Build the training/validate/test datasets\r\n  \r\nFor the cross-validation we split the training set in 80-20.  \r\n\r\n  \r\n```{r CrossVal}\r\n\r\nset.seed(crv$seed) \r\npml_nobs <- nrow(pml_dataset) # 19622 observations \r\npml_sample <- pml_train <- sample(nrow(pml_dataset), 0.8*pml_nobs) # 15697 observations\r\npml_validate <- NULL\r\npml_test <- setdiff(setdiff(seq_len(nrow(pml_dataset)), pml_train), pml_validate) # 3925 observations\r\n\r\n# The following variable selections have been noted.\r\n\r\npml_input <- c(\"roll_belt\", \"pitch_belt\", \"yaw_belt\", \"total_accel_belt\",\r\n     \"gyros_belt_x\", \"gyros_belt_y\", \"gyros_belt_z\", \"accel_belt_x\",\r\n     \"accel_belt_y\", \"accel_belt_z\", \"magnet_belt_x\", \"magnet_belt_y\",\r\n     \"magnet_belt_z\", \"roll_arm\", \"pitch_arm\", \"yaw_arm\",\r\n     \"total_accel_arm\", \"gyros_arm_x\", \"gyros_arm_y\", \"gyros_arm_z\",\r\n     \"accel_arm_x\", \"accel_arm_y\", \"accel_arm_z\", \"magnet_arm_x\",\r\n     \"magnet_arm_y\", \"magnet_arm_z\", \"roll_dumbbell\", \"pitch_dumbbell\",\r\n     \"yaw_dumbbell\", \"total_accel_dumbbell\", \"gyros_dumbbell_x\", \"gyros_dumbbell_y\",\r\n     \"gyros_dumbbell_z\", \"accel_dumbbell_x\", \"accel_dumbbell_y\", \"accel_dumbbell_z\",\r\n     \"magnet_dumbbell_x\", \"magnet_dumbbell_y\", \"magnet_dumbbell_z\", \"roll_forearm\",\r\n     \"pitch_forearm\", \"yaw_forearm\", \"total_accel_forearm\", \"gyros_forearm_x\",\r\n     \"gyros_forearm_y\", \"gyros_forearm_z\", \"accel_forearm_x\", \"accel_forearm_y\",\r\n     \"accel_forearm_z\", \"magnet_forearm_x\", \"magnet_forearm_y\", \"magnet_forearm_z\")\r\n\r\npml_numeric <- c(\"roll_belt\", \"pitch_belt\", \"yaw_belt\", \"total_accel_belt\",\r\n     \"gyros_belt_x\", \"gyros_belt_y\", \"gyros_belt_z\", \"accel_belt_x\",\r\n     \"accel_belt_y\", \"accel_belt_z\", \"magnet_belt_x\", \"magnet_belt_y\",\r\n     \"magnet_belt_z\", \"roll_arm\", \"pitch_arm\", \"yaw_arm\",\r\n     \"total_accel_arm\", \"gyros_arm_x\", \"gyros_arm_y\", \"gyros_arm_z\",\r\n     \"accel_arm_x\", \"accel_arm_y\", \"accel_arm_z\", \"magnet_arm_x\",\r\n     \"magnet_arm_y\", \"magnet_arm_z\", \"roll_dumbbell\", \"pitch_dumbbell\",\r\n     \"yaw_dumbbell\", \"total_accel_dumbbell\", \"gyros_dumbbell_x\", \"gyros_dumbbell_y\",\r\n     \"gyros_dumbbell_z\", \"accel_dumbbell_x\", \"accel_dumbbell_y\", \"accel_dumbbell_z\",\r\n     \"magnet_dumbbell_x\", \"magnet_dumbbell_y\", \"magnet_dumbbell_z\", \"roll_forearm\",\r\n     \"pitch_forearm\", \"yaw_forearm\", \"total_accel_forearm\", \"gyros_forearm_x\",\r\n     \"gyros_forearm_y\", \"gyros_forearm_z\", \"accel_forearm_x\", \"accel_forearm_y\",\r\n     \"accel_forearm_z\", \"magnet_forearm_x\", \"magnet_forearm_y\", \"magnet_forearm_z\")\r\n\r\npml_categoric <- NULL\r\n\r\npml_target  <- \"classe\"\r\npml_risk    <- NULL\r\npml_ident   <- NULL\r\npml_ignore  <- NULL\r\npml_weights <- NULL\r\n\r\n```\r\n\r\n\r\n\r\n\r\n### Random Forest Model  \r\n\r\nWe load the randomForest package and proceed to build our model using 500 trees and 7 variables tried at each split.  \r\n\r\n\r\n```{r RFModel}\r\n# The 'randomForest' package provides the 'randomForest' function.\r\n\r\nlibrary(randomForest, quietly=TRUE)\r\n\r\n# Build the Random Forest model.\r\n\r\nset.seed(crv$seed)\r\npml_rf <- randomForest::randomForest(classe ~ .,\r\n      data=pml_dataset[pml_sample,c(pml_input, pml_target)], \r\n      ntree=500,\r\n      mtry=7,\r\n      importance=TRUE,\r\n      na.action=randomForest::na.roughfix,\r\n      replace=FALSE)\r\n\r\n# Generate textual output of 'Random Forest' model.\r\n\r\npml_rf\r\n\r\n\r\n```\r\n\r\nThe OOB estimate of  error rate (0.41%) is very encouraging and so is the confusion matrix on the training set. We therefore move on to check the performance of our mdel on our cross-validated test-set.  \r\n\r\n\r\n### Evaluate model performance.\r\n\r\n```{r Evaluation, message=FALSE}\r\n\r\n# Generate an Error Matrix for the Random Forest model.\r\n\r\n# Obtain the response from the Random Forest model.\r\n\r\npml_pr <- predict(pml_rf, newdata=na.omit(pml_dataset[pml_test, c(pml_input, pml_target)]))\r\n\r\n# Generate the confusion matrix showing counts.\r\n\r\ntable(na.omit(pml_dataset[pml_test, c(pml_input, pml_target)])$classe, pml_pr,\r\n        dnn=c(\"Actual\", \"Predicted\"))\r\n\r\nlibrary(caret)\r\n\r\naccuracy <- postResample(pml_pr, pml_dataset[pml_test, c(pml_input, pml_target)]$classe)\r\naccuracy\r\nerror <- 1 - as.numeric(confusionMatrix(pml_dataset[pml_test, c(pml_input, pml_target)]$classe, pml_pr)$overall[1])\r\nerror\r\n\r\n\r\n```\r\n\r\nThe accuracy and the out of sample error are, again, satisfying, therefore we generate the predictions on the orginal Test set (which will be separately uploaded and submitted).\r\n\r\n```{r Answers}\r\nanswers <- predict(pml_rf, finalTest)\r\nanswers\r\n```\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}